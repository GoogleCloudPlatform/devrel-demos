{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113ee65a",
   "metadata": {},
   "source": [
    "## How to create a natural language diagnostic agent using Agent Engine and osquery\n",
    "\n",
    "In this notebook you are going to learn how to build an agent to answer questions about the machine it is running in. This is the supporting notebook for my article in https://danicat.dev.\n",
    "\n",
    "Note: For this notebook to work you need to have [osquery](https://osquery.io) installed in your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71618e8b",
   "metadata": {},
   "source": [
    "### Create a Vertex AI agent\n",
    "\n",
    "First we need to install the pre-requisite python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc64b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet google-cloud-aiplatform[agent_engines,langchain]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c357db0",
   "metadata": {},
   "source": [
    "Then select a base model for the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gemini-2.5-flash-preview-05-20\" # feel free to experiment with different models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eecc84",
   "metadata": {},
   "source": [
    "These are just helpers for visualizing the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7e8ae",
   "metadata": {},
   "source": [
    "You can configure model parameters with `model_kwargs` (optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04326884",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    # temperature (float): The sampling temperature controls the degree of\n",
    "    # randomness in token selection.\n",
    "    \"temperature\": 0.20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6695d16",
   "metadata": {},
   "source": [
    "Initialize the Vertex AI client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "vertexai.init(\n",
    "    project=\"daniela-genai-sandbox\",       # Your project ID.\n",
    "    location=\"us-central1\",                # Your cloud region.\n",
    "    staging_bucket=\"gs://danicat-devrel\",  # Your staging bucket.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c8a531",
   "metadata": {},
   "source": [
    "And create an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a69346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai import agent_engines\n",
    "\n",
    "agent = agent_engines.LangchainAgent(\n",
    "    model=model,                # Required.\n",
    "    model_kwargs=model_kwargs,  # Optional.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60f057",
   "metadata": {},
   "source": [
    "You can ask any questions to the agent and it will use the select model to process the answer. You can also configure the model with a prompt or system instructions. Let's start with a simple query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b292bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    input=\"which time is now?\"\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ea93b",
   "metadata": {},
   "source": [
    "The agent cannot respond this query because it doesn't have access to the system clock. At best it will say it can't do, at worst it will hallucinate and give an incorrect response. We can fix this by giving it a tool to retrieve the current time. We are doing this using a regular python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_current_time():\n",
    "    \"\"\"Returns the current time as a datetime object.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        datetime: current time as a datetime type\n",
    "    \"\"\"\n",
    "    return datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd4c11",
   "metadata": {},
   "source": [
    "Now we redefine the agent to use the `get_current_time` function as a tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d39585",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = agent_engines.LangchainAgent(\n",
    "    model=model,                # Required.\n",
    "    model_kwargs=model_kwargs,  # Optional.\n",
    "    tools=[get_current_time]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e44eab",
   "metadata": {},
   "source": [
    "And the response should be much better now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    input=\"which time is now?\"\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f13283",
   "metadata": {},
   "source": [
    "### Retrieving system information\n",
    "\n",
    "Start by installing the python bindings for osquery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d86604",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet osquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f62fb",
   "metadata": {},
   "source": [
    "Let's test it with a simple query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f34d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osquery\n",
    "\n",
    "# Spawn an osquery process using an ephemeral extension socket.\n",
    "instance = osquery.SpawnInstance()\n",
    "instance.open()  # This may raise an exception\n",
    "\n",
    "# Issues queries and call osquery Thrift APIs.\n",
    "instance.client.query(\"select timestamp from time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0debe975",
   "metadata": {},
   "source": [
    "### Connecting the dots\n",
    "\n",
    "Now that osquery is working, let's create a function to call osquery. This will be the `tool` we are giving to our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_osquery(query: str):\n",
    "    \"\"\"Query the operating system using osquery\n",
    "      \n",
    "      This function is used to send a query to the osquery process to return information about the current machine, operating system and running processes.\n",
    "      You can also use this function to query the underlying SQLite database to discover more information about the osquery instance by using system tables like sqlite_master, sqlite_temp_master and virtual tables.\n",
    "\n",
    "      Args:\n",
    "        query: str  A SQL query to one of osquery tables (e.g. \"select timestamp from time\")\n",
    "\n",
    "      Returns:\n",
    "        ExtensionResponse: an osquery response with the status of the request and a response to the query if successful.\n",
    "    \"\"\"\n",
    "    return instance.client.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be042fe",
   "metadata": {},
   "source": [
    "To improve the quality of the responses, we are also going to give the agent the list of tables available in this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb78d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use some python magic to figure out which tables we have in this system\n",
    "response = instance.client.query(\"select name from sqlite_temp_master\").response\n",
    "tables = [ t[\"name\"] for t in response ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9ea03",
   "metadata": {},
   "source": [
    "Now the agent definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "osagent = agent_engines.LangchainAgent(\n",
    "    model = model,\n",
    "    system_instruction=f\"\"\"\n",
    "    You are an agent that answers questions about the machine you are running in.\n",
    "    You should run SQL queries using one or more of the tables to answer the user questions.\n",
    "    Always return human readable values (e.g. megabytes instead of bytes, and formatted time instead of miliseconds)\n",
    "    Be very flexible in your interpretation of the requests. For example, if the user ask for application information, it is acceptable to return information about processes and services. If the user requests resource usage, return BOTH memory and cpu information.\n",
    "    Do not ask the user for clarification.\n",
    "    You have the following tables available to you: \n",
    "    ----- TABLES -----\n",
    "    {tables}\n",
    "    ----- END TABLES -----\n",
    "\n",
    "    Question:\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        call_osquery,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c981a10",
   "metadata": {},
   "source": [
    "All done! We are ready to start asking some questions.\n",
    "\n",
    "Note: sometimes the agent won't get the answer on the first try because it failed to use osquery properly. I recommend trying each prompt a few times to see the different responses it can generate.\n",
    "\n",
    "It is also fun to compare the responses with the numbers in the actual tools available in your operating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = osagent.query(input=\"what is the current time?\")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = osagent.query(input=\"what is the top consuming process?\")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = osagent.query(input=\"computer, run a level 1 diagnostic procedure\")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a97901",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = osagent.query(input=\"can you find anything wrong with my computer?\")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = osagent.query(input=\"computer, do you see any signs of malware running?\")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = osagent.query(input=\"computer, run a system health check\")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7883488f",
   "metadata": {},
   "source": [
    "And we've reached the end of this notebook. Try asking different questions and see how the model behaves. Experiment with different base models, tweaking the system instructions and the model parameters.\n",
    "\n",
    "If you find any interesting prompts and configurations, comment about your results on https://danicat.dev or on my socials. Have fun!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
